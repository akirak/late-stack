---
title: Effect OGP Integration
language: en
draft: true
---

:::warning

Some part of this post has been generated by AI. It is reviewed by human, but
the content may not reflect the actual linguistic proficiency of the author.

:::

This document specifies an Open Graph Protocol (OGP) integration of this blog
system.

## Examples

Here's how the OGP integration works:

::link[https://effect.website]

::link[https://github.com/anthropics/claude-code]

## Purpose: Fetching OGP metadata at build time

Modern blogs are more than static pages—they are hubs that reference videos,
tweets, papers and other rich resources. Showing a preview card for each
external URL greatly improves user experience. Yet fetching metadata **at render
time** is slow and unreliable.

By fetching all metadata of referenced external contents **at build time** and
storing them locally, the application never performs additional network requests
for OGP data. This will significantly improve the user experience of any
frontend application.

## Architecture description

### 1. Bird's-eye view

:::diagram

```d2
direction: right

Markdown: Markdown posts {
  shape: document
}
Pipeline: Collections Pipeline {
  shape: package
}
Extract: extract external links {
  shape: page
}
LinkMetadataService: LinkMetadataService {
  shape: hexagon
}
MetadataCache: MetadataCache {
  shape: hexagon
}
MetadataKvs: SQLite KVS {
  shape: cylinder
}
MetadataFetcher: MetadataFetcher {
  shape: hexagon
}
Internet: {
  shape: cloud
}
PostJson: Post JSON artefacts {
  shape: cylinder
}

Markdown -> Pipeline
Pipeline -> Extract
Pipeline -> LinkMetadataService
LinkMetadataService -> MetadataCache
MetadataCache -> MetadataKvs
LinkMetadataService -> MetadataFetcher
MetadataFetcher -> Internet
MetadataFetcher -> MetadataCache
MetadataCache -> LinkMetadataService
LinkMetadataService -> Pipeline
Pipeline -> PostJson
```

:::

The system follows a layered architecture using Effect's service pattern:

- **LinkMetadataService**: High-level API providing a simple `get(url)` method
- **MetadataCache**: Caching layer with TTL-based expiration (60 days)
- **MetadataKvs**: SQLite-based key-value storage
- **MetadataFetcher**: HTTP client with HTML parsing capabilities

These services live only during the build. At runtime the blog simply reads the pre-fetched metadata already embedded in each post.

### 2. Data model

The `LinkMetadata` schema captures essential OGP fields:

```typescript
interface LinkMetadata {
  canonical?: string // Canonical URL from <link rel="canonical">
  title?: string // From og:title, twitter:title, or <title>
  description?: string // From og:description or twitter:description
  image?: string // From og:image or twitter:image
  imageAlt?: string // From og:image:alt or twitter:image:alt
  imageWidth?: number // From og:image:width
  imageHeight?: number // From og:image:height
  siteName?: string // From og:site_name
  ogType?: OgType // From og:type (e.g., "article", "website")
}
```

The cache stores metadata wrapped in an `Envelope` with creation timestamp:

```typescript
interface Envelope {
  createdAt: Date
  data: LinkMetadata
}
```

This timestamp enables a simple TTL-based cache invalidation strategy (60 days) without complex invalidation rules.

### 3. Service interfaces

**LinkMetadataService** provides a simple API:

```typescript
declare function get(url: string): Effect<Option<LinkMetadata>, never, LinkMetadataService>
```

**MetadataCache** handles persistence:

```typescript
interface MetadataCache {
  get: (url: string) => Effect<Option<Envelope<LinkMetadata>>, KvsError>
  set: (url: string, metadata: LinkMetadata) => Effect<void, KvsError>
}
```

**MetadataFetcher** handles HTTP and parsing:

```typescript
interface MetadataFetcher {
  fetch: (url: string) => Effect<LinkMetadata, FetchError | ParseError>
}
```

The `get` method implements smart caching:

```d2
sequence: get(url)
Client->LinkMetadataService: get(url)
LinkMetadataService->MetadataCache: get(url)
MetadataCache->LinkMetadataService: cached data
LinkMetadataService: check TTL (60 days)
LinkMetadataService->MetadataFetcher: fetch(url) [if stale]
MetadataFetcher->Internet: HTTP GET
Internet->MetadataFetcher: HTML
MetadataFetcher->LinkMetadataService: metadata
LinkMetadataService->MetadataCache: set(url, metadata)
LinkMetadataService->Client: Option<LinkMetadata>
```

The service returns `Option<LinkMetadata>` and never throws. On fetch failure with stale cache, it returns the stale data. This ensures the pipeline continues even if external providers are down.

### 4. Storage layer

The storage uses a generic key-value store abstraction (`MetadataKvs`) implemented with SQLite:

```typescript
interface Kvs<V> {
  get: (key: string) => Effect<Option<V>, KvsError>
  set: (key: string, value: V) => Effect<void, KvsError>
  has: (key: string) => Effect<boolean, KvsError>
  clear: () => Effect<void, KvsError>
  keys: () => Effect<string[], KvsError>
}
```

SQLite was chosen because:

- Single-file, zero-config, battle-tested
- Native JSON column support for structured queries
- Works identically on developer laptops, CI runners, and production
- Located at `data/link-metadata.sqlite` (git-ignored)

The implementation uses:

- JSON serialization for `Envelope<LinkMetadata>` values
- Effect Schema for type-safe encoding/decoding
- Simple key-value table structure

<!--
Need Redis or Postgres?  Just implement the three Store functions and wire a new
layer – no changes required elsewhere.
 -->

### 5. Fetcher implementation

The `MetadataFetcher` implements robust HTML metadata extraction:

**HTTP handling:**

- Maximum 5 redirects
- 10-second timeout
- 1MB response size limit
- Up to 5 retries with exponential backoff
- Only accepts HTTP(S) URLs

**HTML parsing with `html-rewriter-wasm`:**

1. Extract Open Graph tags (`og:*`)
2. Fall back to Twitter Card tags (`twitter:*`)
3. Final fallback to `<title>` element
4. Extract canonical URL from `<link rel="canonical">`
5. Resolve all relative URLs against the base URL

**Error handling:**

```typescript
type FetchError
  = | { _tag: "InvalidUrl" }
    | { _tag: "NetworkError", error: unknown }
    | { _tag: "Timeout" }
    | { _tag: "ResponseTooLarge" }
    | { _tag: "TooManyRedirects" }
    | { _tag: "InvalidContentType" }
```

All errors are typed, allowing the pipeline to gracefully handle failures without crashing the build.

### 6. Integration with Remark

The `remarkLink` plugin integrates OGP fetching into the Markdown pipeline:

**Processing flow:**

1. Collect all `::link` directives during AST traversal
2. Batch fetch metadata with concurrency limit of 5
3. Transform directives based on type:
   - **Block-level** (container/leaf): Generate rich link cards or YouTube embeds
   - **Text-level**: Simple links (no OGP fetching)

**Link card generation:**

- YouTube URLs → Embedded video players
- Other URLs → Rich preview cards with title, description, and image
- Failed fetches → Graceful fallback to plain links

The plugin runs only at build time. All metadata is embedded in the post JSON, eliminating runtime network requests.

### 7. Deployment & caching strategy

**Local development:**

- Database location: `data/link-metadata.sqlite` (git-ignored)
- Persistent across dev server restarts
- 60-day TTL minimizes redundant fetches

**CI/CD (GitHub Actions):**

- Cache database with `actions/cache`
- TTL ensures most builds use cached data
- Reduces API rate limit risks

**Production (Deno Deploy):**

- Database copied to build output during `pnpm build`
- Read-only access at runtime
- No runtime fetching or writes

<!--
### 8. Roadmap

* oEmbed fallbacks for Twitter, SoundCloud, etc.
* `pnpm og:purge` CLI to manually clear the cache.
* Scheduled GitHub Action refreshing stale rows weekly.
* Optional CDN layer for anonymous prod traffic.
 -->

## Credits

The initial idea was drafted with Gemini 2.5 Flash and then refined with OpenAI
o3. After completing the initial implementation, this document has been updated
accordingly.
